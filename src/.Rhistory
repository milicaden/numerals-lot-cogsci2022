}
for(x in c(11:14)){
dre = c(dre, list(c("dre", paste0("word", x), paste0("10+", x%%10))))
}
for(x in c(15)){
dre = c(dre, list(c("dre", paste0("word", x), "3*5")))
}
for(x in c(16:19)){
dre = c(dre, list(c("dre", paste0("word", x), paste0("15+", x%%5))))
}
for(x in c(20)){
dre = c(dre, list(c("dre", paste0("word", x), "1*20")))
}
for(x in c(21:24)){
dre = c(dre, list(c("dre", paste0("word", x), paste0("1*20+", x%%10))))
}
for(x in c(25)){
dre = c(dre, list(c("dre", paste0("word", x), paste0("1*20+","1*5"))))
}
for(x in c(26:29)){
dre = c(dre, list(c("dre", paste0("word", x), paste0("1*20+5+", x%%5))))
}
for(x in c(30)){
dre = c(dre, list(c("dre", paste0("word", x), "1*20+2*5")))
}
for(x in c(31:34)){
dre = c(dre, list(c("dre", paste0("word", x), paste0("1*20+10+", x%%10))))
}
for(x in c(35)){
dre = c(dre, list(c("dre", paste0("word", x), "1*20+15")))
}
for(x in c(36:39)){
dre = c(dre, list(c("dre", paste0("word", x), paste0("1*20+15+",x%%5 ))))
}
for(x in c(40, 60, 80)){
dre = c(dre, list(c("dre", paste0("word", x), paste0(x/20, "*20"))))
}
for(x in c(41:44, 61:64, 81:84)){
dre = c(dre, list(c("dre", paste0("word", x), paste0(x%/%20, "*20+",x%%10))))
}
for(x in c(45, 65, 85)){
dre = c(dre, list(c("dre", paste0("word", x), paste0(x%/%20, "*20+1*5"))))
}
for(x in c(46:49, 66:69, 86:89)){
dre = c(dre, list(c("dre", paste0("word", x), paste0(x%/%20, "*20+5+",x%%5))))
}
for(x in c(50, 70, 90)){
dre = c(dre, list(c("dre", paste0("word", x), paste0(x%/%20, "*20+2*5"))))
}
for(x in c(51:54, 71:74, 91:94)){
dre = c(dre, list(c("dre", paste0("word", x), paste0(x%/%20, "*20+10+",x%%10))))
}
for(x in c(55, 75, 95)){
dre = c(dre, list(c("dre", paste0("word", x), paste0(x%/%20, "*20+15"))))
}
for(x in c(56:59, 76:79, 96:99)){
dre = c(dre, list(c("dre", paste0("word", x), paste0(x%/%20, "*20+15+",x%%5))))
}
natural = c(natural, dre)
###########################
# Type 5-Mangap-Mbula
###########################
#Mangap-Mbula
for(y in c("mmb")){
assign(y, c())
for(x in c(1:4)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), x))))
}
for(x in c(6:9)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0("1*5+", x%%5)))))
}
for(x in c(11:14)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0("2*5+", x%%10)))))
}
for(x in c(5, 10)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0(x/5, "*5")))))
}
for(x in c(15)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0("(2+1)","*5")))))
}
for(x in c(16:19)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0("3*5+", x%%5)))))
}
for(x in c(20, 40, 60, 80)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0(x/20, "*20")))))
}
for(x in c(21:24, 41:44, 61:64, 81:84)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0(x%/%20, "*20+",x%%10)))))
}
for(x in c(25, 45, 65, 85)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0(x%/%20, "*20+1*",x%%10)))))
}
for(x in c(26:29, 46:49, 66:69, 86:89)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0(x%/%20, "*20+1*5+",x%%5)))))
}
for(x in c(30, 50, 70, 90)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0(x%/%20, "*20+2*5")))))
}
for(x in c(31:34, 51:54, 71:74, 91:94)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0(x%/%20, "*20+2*5+",x%%10)))))
}
for(x in c(35, 55, 75, 95)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0(x%/%20, "*20+(2+1)*5")))))
}
for(x in c(36:39, 56:59, 76:79, 96:99)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0(x%/%20, "*20+(2+1)*5+",x%%5)))))
}
natural = c(natural, eval(parse(text = y)))
}
###########################
#
# Type 6: other bases
#
###########################
###########################
# Type 6-Haida
###########################
#Haida
# 9 = 10-1. Mix of decimal and vigesimal
hai = c()
for(x in c(1:8,10)){
hai = c(hai, list(c("hai", paste0("word", x), x)))
}
for(x in c(9)){
hai = c(hai, list(c("hai", paste0("word", x), "10-1")))
}
for(x in c(11:18)){
hai = c(hai, list(c("hai", paste0("word", x), paste0("10+", x%%10))))
}
for(x in c(19)){
hai = c(hai, list(c("hai", paste0("word", x), "10+(10-1)")))
}
for(x in c(20,40,60,80)){
hai = c(hai, list(c("hai", paste0("word", x), paste0(x/20, "*20"))))
}
for(x in c(30,50,70)){
hai = c(hai, list(c("hai", paste0("word", x), paste0(x/10, "*10"))))
}
for(x in c(90)){
hai = c(hai, list(c("hai", paste0("word", x), paste0("(10-1)", "*10"))))
}
for(x in c(21:28,41:48,61:68,81:88)){
hai = c(hai, list(c("hai", paste0("word", x), paste0(x%/%20, "*20+", x%%10))))
}
for(x in c(31:38,51:58,71:78)){
hai = c(hai, list(c("hai", paste0("word", x), paste0(x%/%10, "*10+", x%%10))))
}
for(x in c(29)){
hai = c(hai, list(c("hai", paste0("word", x), "1*20+(10-1)")))
}
for(x in c(39)){
hai = c(hai, list(c("hai", paste0("word", x), "3*10+(10-1)")))
}
for(x in c(49)){
hai = c(hai, list(c("hai", paste0("word", x), "2*20+(10-1)")))
}
for(x in c(59)){
hai = c(hai, list(c("hai", paste0("word", x), "5*10+(10-1)")))
}
for(x in c(69)){
hai = c(hai, list(c("hai", paste0("word", x), "3*20+(10-1)")))
}
for(x in c(79)){
hai = c(hai, list(c("hai", paste0("word", x), "7*10+(10-1)")))
}
for(x in c(89)){
hai = c(hai, list(c("hai", paste0("word", x), "4*20+(10-1)")))
}
for(x in c(91:98)){
hai = c(hai, list(c("hai", paste0("word", x), paste0("(10-1)*10+", x%%10))))
}
for(x in c(99)){
hai = c(hai, list(c("hai", paste0("word", x), "(10-1)*10+(10-1)")))
}
natural = c(natural, hai)
###########################
# Type 6-Kilivila
###########################
#Kilivila (klv)
#Decimal, but building 6-9, 10 and 20 single morphemes, 100 = 1*100
klv = c()
for(x in c(1:5)){
klv = c(klv, list(c("klv", paste0("word", x), x)))
}
for(x in c(6:9)){
klv = c(klv, list(c("klv", paste0("word", x), paste0("5+", x%%5))))
}
for(x in c(11:15, 21:25, 31:35, 41:45, 51:55)){
klv = c(klv, list(c("klv", paste0("word", x), paste0(x%/%10, "*10+",x%%10))))
}
for(x in c(16:19, 26:29, 36:39, 46:49, 56:59)){
klv = c(klv, list(c("klv", paste0("word", x), paste0(x%/%10, "*10+5+",x%%5))))
}
for(x in c(10, 20, 30, 40, 50)){
klv = c(klv, list(c("klv", paste0("word", x), paste0(x/10, "*10"))))
}
for(x in c(60, 70, 80, 90)){
klv = c(klv, list(c("klv", paste0("word", x), paste0("5*10+", (x-50)/10, "*10"))))
}
for(x in c(61:65, 71:75, 81:85, 91:95)){
klv = c(klv, list(c("klv", paste0("word", x), paste0("5*10+", (x - x%%10 -50)/10, "*10+",x%%10))))
}
for(x in c(66:69, 76:79, 86:89, 96:99)){
klv = c(klv, list(c("klv", paste0("word", x), paste0("5*10+", (x - x%%10 -50)/10, "*10+5+",x%%5))))
}
natural = c(natural, klv)
###########################
# Type 6-Tommo So
###########################
#Tommo So (tms)
#Like Mandarin up to 80, then 80+10 = 90, 100 = 80 +20 etc
for(y in c("tms")){
assign(y, c())
for(x in c(1:10, 80)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), x))))
}
for(x in c(11:19)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0("10+", x%%10)))))
}
for(x in c(20,30,40,50,60,70)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0(x/10, "*10")))))
}
for(x in c(90)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), "80+10"))))
}
for(x in c(21:29,31:39,41:49,51:59,61:69,71:79)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0(x%/%10, "*10+", x%%10)))))
}
for(x in c(81:89)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0("80+", x%%10)))))
}
for(x in c(91:99)){
assign(y, c(eval(parse(text = y)), list(c(y, paste0("word", x), paste0("80+10+", x%%10)))))
}
natural = c(natural, eval(parse(text = y)))
}
###########################
# Type 6-Khalaj
###########################
#Khalaj (khl)
khl = c()
for(x in c(1:10, 20,30,40,50)){
khl = c(khl, list(c("khl", paste0("word", x), x)))
}
for(x in c(11:19)){
khl = c(khl, list(c("khl", paste0("word", x), paste0("10+", x%%10))))
}
for(x in c(21:29)){
khl = c(khl, list(c("khl", paste0("word", x), paste0("20+", x%%10))))
}
for(x in c(31:39)){
khl = c(khl, list(c("khl", paste0("word", x), paste0("30+", x%%10))))
}
for(x in c(41:49)){
khl = c(khl, list(c("khl", paste0("word", x), paste0("40+", x%%10))))
}
for(x in c(51:59)){
khl = c(khl, list(c("khl", paste0("word", x), paste0("50+", x%%10))))
}
for(x in c(60,70,80,90)){
khl = c(khl, list(c("khl", paste0("word", x), paste0("50+", x-50))))
}
for(x in c(61:69,71:79,81:89,91:99)){
khl = c(khl, list(c("khl", paste0("word", x), paste0("50+", (x%/%10-5)*10, "+", x%%10))))
}
natural = c(natural, khl)
#Danish
#Danish (dsh)
dsh = c()
for(x in c(1:10, 11, 20)){
dsh = c(dsh, list(c("dsh", paste0("word", x), x)))
}
for(x in c(12:19)){
dsh = c(dsh, list(c("dsh", paste0("word", x), paste0("10+", x%%10))))
}
for(x in c(21:29)){
dsh = c(dsh, list(c("dsh", paste0("word", x), paste0("20+", x%%10))))
}
for(x in c(30)){
dsh = c(dsh, list(c("dsh", paste0("word", x), "3*10")))
}
for(x in c(31:39)){
dsh = c(dsh, list(c("dsh", paste0("word", x), paste0("3*10+", x%%10))))
}
for(x in c(40)){
dsh = c(dsh, list(c("dsh", paste0("word", x), "4*10")))
}
for(x in c(41:49)){
dsh = c(dsh, list(c("dsh", paste0("word", x), paste0("4*10+", x%%10))))
}
for(x in c(50)){
dsh = c(dsh, list(c("dsh", paste0("word", x), "(3-1/2)*20")))
}
for(x in c(51:59)){
dsh = c(dsh, list(c("dsh", paste0("word", x), paste0("(3-1/2)*20+", x%%10))))
}
for(x in c(60)){
dsh = c(dsh, list(c("dsh", paste0("word", x), "3*20")))
}
for(x in c(61:69)){
dsh = c(dsh, list(c("dsh", paste0("word", x), paste0("3*20+", x%%10))))
}
for(x in c(70)){
dsh = c(dsh, list(c("dsh", paste0("word", x), "(4-1/2)*20")))
}
for(x in c(71:79)){
dsh = c(dsh, list(c("dsh", paste0("word", x), paste0("(4-1/2)*20+", x%%10))))
}
for(x in c(80)){
dsh = c(dsh, list(c("dsh", paste0("word", x), "4*20")))
}
for(x in c(81:89)){
dsh = c(dsh, list(c("dsh", paste0("word", x), paste0("4*20+", x%%10))))
}
for(x in c(90)){
dsh = c(dsh, list(c("dsh", paste0("word", x), "(5-1/2)*20")))
}
for(x in c(91:99)){
dsh = c(dsh, list(c("dsh", paste0("word", x), paste0("(5-1/2)*20+", x%%10))))
}
natural = c(natural, dsh)
# Create a df from a list of vectors
natural_df = as.data.frame(do.call(rbind, natural))
colnames(natural_df) <- c("language", "word", "morphology")
length(unique(natural_df$language))
natural_df$extension = 0
for(i in 1:length(natural_df$morphology)){
natural_df[['extension']][i] = eval(parse(text = as.character(natural_df[['morphology']][i])))
}
# Generate fake languages and their items
natural_filename = paste0(Folder, "natural_languages.csv")
write.csv(natural_df, natural_filename, row.names=FALSE)
source("./Numerals_functions.R")
options(scipen = 999)
natural_languages = read.csv("../data/natural_languages.csv", header = TRUE)
####################################
# Check that the formula computes the extension correctly
####################################
errors = subset(natural_languages, extension >99)
natural_languages$correct_extension = as.numeric(gsub("word", "", natural_languages$word))
natural_languages$extension_check = natural_languages$correct_extension == natural_languages$extension
errors = subset(natural_languages, extension_check == FALSE)
####################################
# Check that there is exactly 99 words for each language
####################################
word_numbers = natural_languages %>%
group_by(language) %>%
summarise(count=n())
errors = subset(word_numbers, !(count == 99))
####################################
# Check that there is no duplicates within language
####################################
word_numbers_within_language = natural_languages %>%
group_by(language, word) %>%
summarise(count=n())
errors = subset(word_numbers_within_language, !(count == 1))
library(plyr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(rje)
Folder = "../data/"
####################################
#Artificial language data
####################################
artificial_language = c()
for(w in 1:99){
word = paste0("word", w)
extension = w
artificial_language <- c(artificial_language, list(c(word, extension)))
}
# Create a df from a list of vectors
artificial_df = as.data.frame(do.call(rbind, artificial_language))
colnames(artificial_df) <- c("word", "extension")
artificial_df$language = "artificial_language"
#transforming to strings because lists cannot be written in a csv
artificial_df <- apply(artificial_df,2,as.character)
# Generate fake languages and their items
artifical_filename = paste0(Folder, "artificial_languages.csv")
write.csv(artificial_df, artifical_filename, row.names=FALSE)
library(plyr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(rje)
library(rlist)
library(stringr)
library(purrr)
source("./Numerals_functions.R")
####################################
# Morphology to LoT
####################################
# Useful version of as.numeric (as.numeric annoyingly can change values if applied to factors...)
as.numeric2 = function(x){
return(as.numeric(as.character(x)))
}
natural_lang = read.csv('../data/natural_languages.csv', header=TRUE)
dictionary = read.csv('../data/shortest_LOT_descriptions.csv', header=TRUE)
LoT_list = complexities_list()
for(i in 1:length(LoT_list)){
LoT_list[i] = paste0('complexity', LoT_list[i])
}
for(x in LoT_list){
natural_lang[[x]] = 0
}
for(complexity in LoT_list){
for(i in 1:length(natural_lang$morphology)){
j1 = lengths(regmatches(natural_lang$morphology[i], gregexpr('*', natural_lang$morphology[i], fixed=TRUE)))
natural_lang[[complexity]][i] = natural_lang[[complexity]][i] + j1
j2 = lengths(regmatches(natural_lang$morphology[i], gregexpr('+', natural_lang$morphology[i], fixed=TRUE)))
natural_lang[[complexity]][i] = natural_lang[[complexity]][i] + j2
j3 = lengths(regmatches(natural_lang$morphology[i], gregexpr('-', natural_lang$morphology[i], fixed=TRUE)))
natural_lang[[complexity]][i] = natural_lang[[complexity]][i] + j3
j4 = lengths(regmatches(natural_lang$morphology[i], gregexpr('/', natural_lang$morphology[i], fixed=TRUE)))
natural_lang[[complexity]][i] = natural_lang[[complexity]][i] + j4
for(n in 1:99){#nb: condition around n makes sure e.g. 1s are not counted in 11
k = lengths(regmatches(natural_lang$morphology[i], gregexpr(paste0('(?<![0-9])', n, '(?![0-9])'), natural_lang$morphology[i], perl = TRUE)))
if(k > 0){
comp_current_df = subset(dictionary, extension == n)
comp_current = comp_current_df[1, complexity]
natural_lang[[complexity]][i] = natural_lang[[complexity]][i] + k*comp_current
}
}
}
}
####################################
# LoT descriptions of numerals for natural languages
####################################
write.csv(natural_lang,'../data/natural_lang_LOT_encodings.csv',row.names=FALSE)
source("./Numerals_functions.R")
options(scipen = 999)
####################################
# Import languages and LoT descriptions
####################################
Folder = "../data/"
artificial_languages = read.csv("../data/artificial_languages.csv", header = TRUE)
artificial_languages$type = "artificial"
minimum_desc= read.csv("../data/shortest_LOT_descriptions.csv", header = TRUE)
artificial_languages = merge(artificial_languages, minimum_desc, by = c("extension"))
artificial_languages$morphology = NA
natural_languages = read.csv("../data/natural_lang_LOT_encodings.csv", header = TRUE)
natural_languages$type = "natural"
all_languages = rbind(artificial_languages, natural_languages)
####################################
# Complexity
####################################
# Function 'complexity' defined in Numerals_functions
# Store different complexity measures in vectors
generate_complexities = TRUE
complexities_filename = paste0(Folder, "languages_complexities_all_LOTs_use_complexity.csv")
if(generate_complexities){
complexities = complexities_list()
# stores all LoT combinations in the format LOTprimitives_5 weights (primitive, +, -, successor, higher)
for(i in complexities){
nam <- paste0("languages_complexity", i)
assign(nam, c())
}
type = c()
languages = c()
for(lang in unique(all_languages$language)){
languages = c(languages, lang)
type = c(type, subset(all_languages, language == lang)[[1,c("type")]])
for(i in complexities){
nam <- paste0("languages_complexity", i)
assign(nam, append(eval(parse(text = nam)), use_weighted_complexity(lang, all_languages, paste0("complexity", i))))
}
} #computes languages' complexity for each LoT combination
# Store complexity measures in a df
langs_complexity = cbind(as.data.frame(languages), as.data.frame(type))
for(i in complexities){
nam <- paste0("languages_complexity", i)
current_df = as.data.frame(eval(parse(text = nam)))
colnames(current_df) <- c(nam)
langs_complexity = cbind(langs_complexity, current_df)
}
write.csv(langs_complexity, complexities_filename, row.names=FALSE)
} else {
langs_complexity = read.csv(complexities_filename)
}
source("./Numerals_functions.R")
options(scipen = 999)
####################################
# USE COMPLEXITY
####################################
languages_complexity = read.csv('../data/languages_complexities_all_LOTs_use_complexity.csv', header=TRUE)
####################################
# Pareto computations
####################################
#Import 3 paretos and compute and store distances for each
complexities = complexities_list() #complexity stores all LoT combinations in the format LOTprimitives_5 weights (primitive, +, -, successor, higher)
for(complexity in complexities){
assign(paste0('natural_distances', complexity), paste0("../data/natural_distances_pareto", complexity, ".csv") )
assign(paste0('natural', complexity), complexity.dist(subset(languages_complexity, type == "natural"), subset(languages_complexity, type == "artificial"), paste0("languages_complexity", complexity)))
write.csv(eval(parse(text = paste0('natural', complexity))), eval(parse(text = paste0('natural_distances', complexity))), row.names=FALSE)
}
LoTs = c()
average_distances = c()
for(complexity in complexities){
LoTs = c(LoTs, complexity)
current_df = eval(parse(text = paste0('natural', complexity)))
average_distances = c(average_distances, mean(current_df$distance))
}
LoTs_minimals_tokens_df = cbind(as.data.frame(LoTs), as.data.frame(average_distances))
#rankings
LoTs_minimals_tokens_df = LoTs_minimals_tokens_df[order(average_distances),]
write.csv(LoTs_minimals_tokens_df,'../data/LoTs_distances_from_dominant.csv' , row.names=FALSE)
# Histogram of distances
p = ggplot(LoTs_minimals_tokens_df, aes(x=average_distances)) +
geom_histogram(binwidth=.01, colour="black", fill="white")+
scale_y_continuous(breaks=c(1,2,3,4,5,6,7,8,9,10,11,12,13)) + labs(x= "Average relativized distance")
print(p)
View(LoTs_minimals_tokens_df)
